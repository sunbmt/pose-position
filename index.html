<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Teachable Machine Pose Model</title>
  <style>
    body {
      font-family: 'Segoe UI', sans-serif;
      background: linear-gradient(135deg, #74ABE2, #5563DE);
      margin: 0;
      padding: 0;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      color: #fff;
    }

    .container {
      background: rgba(255, 255, 255, 0.1);
      padding: 20px 30px;
      border-radius: 16px;
      text-align: center;
      box-shadow: 0 8px 20px rgba(0,0,0,0.3);
      backdrop-filter: blur(8px);
      width: 350px;
    }

    h1 {
      font-size: 22px;
      margin-bottom: 20px;
    }

    button {
      background: #00c6ff;
      border: none;
      color: #fff;
      padding: 10px 18px;
      margin: 8px;
      border-radius: 8px;
      cursor: pointer;
      font-size: 15px;
      transition: all 0.3s ease;
    }

    button:hover {
      background: #0072ff;
      transform: scale(1.05);
    }

    canvas {
      border-radius: 12px;
      background: #fff;
      margin: 15px 0;
      width: 100%;
      max-width: 500px;
      height: auto;
    }

    #label-container {
      margin-top: 10px;
      font-size: 14px;
      text-align: left;
    }

    #label-container div {
      background: rgba(0,0,0,0.3);
      margin: 4px 0;
      padding: 6px 10px;
      border-radius: 6px;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>Teachable Machine Pose Model</h1>
    <button type='button' onclick='startWebcam()'>Start Webcam</button>
    <button type='button' onclick='document.getElementById("imageInput").click()'>Upload Image</button>
    <input type="file" id="imageInput" accept="image/*" style="display:none" onchange="predictImage(event)">

    <canvas id='canvas' width="500" height="500"></canvas>
    <div id='label-container'></div>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8.3/dist/teachablemachine-pose.min.js"></script>

  <script>
    const URL = "https://teachablemachine.withgoogle.com/models/Il0Hcg1fQ/";
    let model, webcam, ctx, labelContainer, maxPredictions;



let audioCtx;

let lastSpoken = { cui: 0, gio2tay: 0, unlock: 0 };
function speak(text, id = "general") {
    const now = Date.now();
    if (!lastSpoken[id] || now - lastSpoken[id] > 4000) {

        window.speechSynthesis.cancel();

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = "en-US";
        utterance.rate = 1;
        utterance.pitch = 1;

        utterance.onstart = () => console.log("üîä B·∫Øt ƒë·∫ßu ph√°t:", text);
        utterance.onend = () => console.log("‚úÖ K·∫øt th√∫c ph√°t:", text);

        window.speechSynthesis.speak(utterance);
        lastSpoken[id] = now;
    }
}

    function unlockSpeech(message) {
        speak(message, "unlock");
    }

function normalizeClassName(name) {
    return name
        .toLowerCase()
        .normalize("NFD").replace(/[\u0300-\u036f]/g, "") 
        .trim();
}


    async function loadModel() {
        if (!model) {
            const modelURL = URL + "model.json";
            const metadataURL = URL + "metadata.json";
            model = await tmPose.load(modelURL, metadataURL);
            maxPredictions = model.getTotalClasses();
            labelContainer = document.getElementById("label-container");
            labelContainer.innerHTML = "";
            for (let i = 0; i < maxPredictions; i++) {
                labelContainer.appendChild(document.createElement("div"));
            }
        }
    }

async function startWebcam() {
  try {
    unlockSpeech("H·ªá th·ªëng nh·∫≠n di·ªán t∆∞ th·∫ø ƒë√£ kh·ªüi ƒë·ªông");
    await loadModel();

    const flip = true;
    webcam = new tmPose.Webcam(500, 500, flip);
    await webcam.setup(); // xin quy·ªÅn camera
    await webcam.play();  // b·∫≠t camera
    setTimeout(() => window.requestAnimationFrame(loop), 500);

    // th√™m video v√†o trang ƒë·ªÉ nh√¨n th·∫•y h√¨nh ·∫£nh
    document.querySelector(".container").appendChild(webcam.canvas);

    // ƒë·∫∑t k√≠ch th∆∞·ªõc v√† context
    const canvas = document.getElementById("canvas");
    canvas.width = 500;
    canvas.height = 500;
    ctx = canvas.getContext("2d");

    // b·∫Øt ƒë·∫ßu v√≤ng l·∫∑p nh·∫≠n di·ªán
    setTimeout(() => window.requestAnimationFrame(loop), 500);
  } catch (err) {
    console.error(err);
    alert("‚ùå Kh√¥ng th·ªÉ truy c·∫≠p camera. H√£y ki·ªÉm tra quy·ªÅn ho·∫∑c th·ª≠ ch·∫°y tr√™n HTTPS/localhost.");
  }
}


    async function loop() {
        webcam.update();
        await predictWebcam();
        window.requestAnimationFrame(loop);
    }

    async function predictWebcam() {
        const { pose, posenetOutput } = await model.estimatePose(webcam.canvas);
        const prediction = await model.predict(posenetOutput);

for (let i = 0; i < maxPredictions; i++) {
    const classPrediction = prediction[i].className + ": " + prediction[i].probability.toFixed(2);
    labelContainer.childNodes[i].innerHTML = classPrediction;

    console.log("Class:", prediction[i].className, "Prob:", prediction[i].probability.toFixed(2));

const cls = normalizeClassName(prediction[i].className);

if (cls === "cui" && prediction[i].probability > 0.8) {
    console.log("üö® Ph√°t hi·ªán: C√öI (prob=" + prediction[i].probability.toFixed(2) + ")");
    speak("You are stooping", "cui");
}
if (cls === "gio 2 tay" && prediction[i].probability > 0.8) {
    console.log("üö® Ph√°t hi·ªán: GI∆† 2 TAY (prob=" + prediction[i].probability.toFixed(2) + ")");
    speak("You are raising both hands", "gio2tay");
}

}



        }
        drawPose(pose, webcam.canvas);
    

    async function predictImage(event) {

        await loadModel();
        const file = event.target.files[0];
        if (!file) return;

        const img = new Image();
        img.onload = async () => {
            const canvas = document.getElementById("canvas");
            canvas.width = img.width;
            canvas.height = img.height;
            ctx = canvas.getContext("2d");
            ctx.drawImage(img, 0, 0);

            const { pose, posenetOutput } = await model.estimatePose(img);
            const prediction = await model.predict(posenetOutput);

for (let i = 0; i < maxPredictions; i++) {
    const classPrediction = prediction[i].className + ": " + prediction[i].probability.toFixed(2);
    labelContainer.childNodes[i].innerHTML = classPrediction;

    console.log("Class:", prediction[i].className, "Prob:", prediction[i].probability.toFixed(2));
const cls = normalizeClassName(prediction[i].className);

if (cls === "cui" && prediction[i].probability > 0.8) {
    console.log("üö® Ph√°t hi·ªán: C√öI (prob=" + prediction[i].probability.toFixed(2) + ")");
    speak("You are stooping", "cui");
}
if (cls === "gio 2 tay" && prediction[i].probability > 0.8) {
    console.log("üö® Ph√°t hi·ªán: GI∆† 2 TAY (prob=" + prediction[i].probability.toFixed(2) + ")");
    speak("You are raising both hands", "gio2tay");
}

}
            drawPose(pose, img);
        };
        img.src = window.URL.createObjectURL(file);
    }

    function drawPose(pose, source) {
        ctx.drawImage(source, 0, 0, ctx.canvas.width, ctx.canvas.height);
        if (pose) {
            const minPartConfidence = 0.5;
            tmPose.drawKeypoints(pose.keypoints, minPartConfidence, ctx);
            tmPose.drawSkeleton(pose.keypoints, minPartConfidence, ctx);
        }
    }
  </script>
</body>
</html>
